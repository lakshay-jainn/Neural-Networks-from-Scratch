{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1625d13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26ce9a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3ce2b10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images = train_images.reshape(train_images.shape[0],-1)\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f264a430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images = test_images.reshape(test_images.shape[0],-1)\n",
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f326e713",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_images\n",
    "Y_train = train_labels\n",
    "\n",
    "X_test = test_images\n",
    "Y_test = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "861732c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing input so that softmax doesnt give wrong output\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e54ff46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting y_train to one hot vector\n",
    "num_classes = np.max(Y_train) + 1\n",
    "y_one_hot_train = np.eye(num_classes)[Y_train]\n",
    "y_one_hot_test  = np.eye(num_classes)[Y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57fe5b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115fd1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation function for hidden layer\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33144774",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(X):\n",
    "    # subtract row-wise max for stability as layer powers on e could cause overflow or underflow\n",
    "    exp_shifted = np.exp(X - np.max(X, axis=1, keepdims=True))\n",
    "    return exp_shifted / np.sum(exp_shifted, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e167dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = np.random.randn(X_train.shape[1], 256) * 0.01\n",
    "B1 = np.zeros((1,256))\n",
    "\n",
    "W2 = np.random.randn(256, 10) * 0.01\n",
    "B2 = np.zeros((1,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e66b8c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('trained_params.npz')\n",
    "W1 = data[\"W1\"]\n",
    "B1 = data[\"B1\"]\n",
    "\n",
    "W2 = data[\"W2\"]\n",
    "B2 = data[\"B2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1fd0206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 256)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((X_train @ W1) + B1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "471dc69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardPass(activation1,activation2,X_train,W1,B1,W2,B2):\n",
    "    #predicted values\n",
    "    Z1 = (X_train @ W1) + B1\n",
    "    A1 = activation1(Z1)\n",
    "    Z2 = (A1 @ W2) + B2\n",
    "    A2 = activation2(Z2)\n",
    "    return A1,A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9319bb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestNN(X_train):\n",
    "    activation1 = sigmoid\n",
    "    activation2 = softmax\n",
    "    A1,A2 = forwardPass(activation1,activation2,X_train,W1,B1,W2,B2)\n",
    "\n",
    "    \n",
    "    return A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3725b8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BinaryBackwardPass(Y_actual,A1,W2,A2,X_train):\n",
    "    m = X_train.shape[0]\n",
    "    Y_pred = A2\n",
    "\n",
    "    # (n,1)\n",
    "    dL_dA2 = (Y_pred - Y_actual)\n",
    "    \n",
    "    #(n,1)\n",
    "    dL_dZ2 =  A2 - Y_actual\n",
    "    \n",
    "    ### dL_dW2 , dL_dB2\n",
    "\n",
    "    #(256,1)\n",
    "    dL_dW2 = (A1.T @ dL_dZ2)/m\n",
    "\n",
    "\n",
    "    dL_dB2 = np.sum((dL_dZ2 * 1),axis = 0,keepdims=True) /m\n",
    "\n",
    "    ### dL_dW1 , dL_dB1\n",
    "\n",
    "    #(n,256)\n",
    "    dL_dA1 = dL_dZ2 @ W2.T\n",
    "    #(n,256)\n",
    "    dL_dZ1 = dL_dA1 * (A1 * (1 - A1))\n",
    "\n",
    "    #(784,256)\n",
    "    dL_dW1 = (X_train.T @ dL_dZ1)/m\n",
    "\n",
    "    #(n,256)\n",
    "    dL_dB1 = np.sum((dL_dZ1 * 1),axis=0,keepdims=True) /m\n",
    "\n",
    "    return dL_dW2,dL_dB2,dL_dW1,dL_dB1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c66678f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backwardPass(Y_actual,A1,W2,A2,X_train):\n",
    "    m = X_train.shape[0]\n",
    "    # X_train = (n,784)\n",
    "\n",
    "    #(n,10)\n",
    "    dL_dZ2 = (A2 - Y_actual)\n",
    "\n",
    "    #(10,256)\n",
    "    dL_dW2 = (A1.T @ dL_dZ2) / m # /m for stability\n",
    "\n",
    "    #(1,10)\n",
    "    dL_dB2 = np.sum(dL_dZ2 * 1,axis=0,keepdims=True) / m # /m for stability\n",
    "\n",
    "    #(n,256)\n",
    "    dL_dA1 = (dL_dZ2 @ W2.T)\n",
    "\n",
    "    #(n,256)\n",
    "    dL_dZ1 = dL_dA1 * (A1 * (1 - A1))\n",
    "\n",
    "    #(784,256)\n",
    "    dL_dW1 = (X_train.T @ dL_dZ1) / m # /m for stability\n",
    "\n",
    "    #(1,256)\n",
    "    dL_dB1 = np.sum(dL_dZ1 * 1,axis = 0,keepdims=True) / m # /m for stability\n",
    "    \n",
    "    return dL_dW2,dL_dB2,dL_dW1,dL_dB1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6fa25a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateParams(dL_dW2,dL_dB2,dL_dW1,dL_dB1, W1,W2,B1,B2,learning_rate):\n",
    "    W1 = W1 - (learning_rate * dL_dW1)\n",
    "    B1 = B1 - (learning_rate * dL_dB1)\n",
    "\n",
    "    W2 = W2 - (learning_rate * dL_dW2)\n",
    "    B2 = B2 - (learning_rate * dL_dB2)\n",
    "    \n",
    "    return W1, B1, W2, B2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96df886e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binaryCrossEntropy(Y_pred,Y_actual):\n",
    "    m = Y_actual.shape[0]\n",
    "    first_part = Y_actual*np.log(Y_pred)\n",
    "    second_part = (1 - Y_actual)*np.log(1 - Y_pred)\n",
    "    return  (-1) * (1/m) * np.sum((first_part + second_part),axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b99368b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_loss_onehot(y_pred, y_true):\n",
    "\n",
    "    y_pred = np.clip(y_pred, 1e-12, 1.0)\n",
    "    loss = -np.sum(y_true * np.log(y_pred)) / y_pred.shape[0]\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7723d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44644836492613055\n",
      "nice one\n",
      "0.4257611656894478\n",
      "nice one\n",
      "0.4091316864423833\n",
      "nice one\n",
      "0.3954814078680738\n",
      "nice one\n",
      "0.3840591523883693\n",
      "nice one\n",
      "0.3743340247204024\n",
      "nice one\n",
      "0.3659258435025068\n",
      "nice one\n",
      "0.35855845739549713\n",
      "nice one\n",
      "0.3520281299198976\n",
      "nice one\n",
      "0.3461820356681281\n",
      "nice one\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "learning_rate = 0.1\n",
    "for i in range(epochs):\n",
    "    A1,A2 = forwardPass(sigmoid,softmax,X_train,W1,B1,W2,B2)\n",
    "\n",
    "    dL_dW2,dL_dB2,dL_dW1,dL_dB1 = backwardPass(y_one_hot_train,A1,W2,A2,X_train)\n",
    "\n",
    "    W1, B1, W2, B2 = updateParams(dL_dW2,dL_dB2,dL_dW1,dL_dB1, W1,W2,B1,B2,learning_rate)\n",
    "    if (i%100 == 0):\n",
    "        # mse = binaryCrossEntropy(A2, Y_train)\n",
    "        # print(mse)\n",
    "        print(softmax_loss_onehot(A2,y_one_hot_train))\n",
    "        print(\"nice one\")\n",
    "     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d95832ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = TestNN(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d106b111",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = np.argmax(Y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "90b25b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = np.mean(predicted_classes == Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dc61332c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your trained model is 90.6% accurate on unseen test data\n"
     ]
    }
   ],
   "source": [
    "acc_pct = str(round(accuracy * 100,2)) + \"%\"\n",
    "print(\"your trained model is\",acc_pct, \"accurate on unseen test data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c34c9f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " array([1033, 1153, 1001, 1013, 1006,  857,  966, 1008,  956, 1007]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(predicted_classes, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1564fdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('trained_params.npz', W1=W1, B1=B1, W2=W2, B2=B2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
